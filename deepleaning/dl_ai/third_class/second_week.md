### 进行错误分析

比如在cat分类器的分类错误中，如果发现有很多狗识别成了猫，那就需要考虑增加关于狗的数据。

当然，这里也可以估算下，通过增加狗的识别性能，可以提升多少cat分类器。

如果有多个思路的时候，可以手动画个表，然后比对下，应该先实现拿些。。

![](jpg/3.JPG)

比如像这样，然后计算下可以提高多少。

### 清理错误标签的数据

有的数据被标记错了。叫做**错误标记**。

首先，深度学习，对于这种不怎么偏离统计意义上的**随机错误(random errors)**，并不是那么敏感，一般而言不用特别在意。

但对于**系统错误(system errors)**就不那么好了。比如一直把白狗标记为猫，那就很糟糕了。

同样也可以在上面的表格中增加这种参数。

### 快速构建第一个模型，然后迭代

反正对于研究、开发来说都很有用就是了。

### 在不同的分布中进行训练测试

![](jpg/4.JPG)

比如目标为右边的移动端app，那么就需要考虑关于开发集、测试集中关于数据来源的问题。

不能直接打散放的原因在于，随机会导致开发集中的目标很少，同时这也会导致开发迭代走向了错误的道路。

![](jpg/5.JPG)

<!--为什么不考虑对这个进行加权呢？-->

### 不同分布数据中偏差与方差分析法

如果对于类似上述描述中的分猫器，训练集为清晰的图，开发集为不清晰的。

那么这里有两个变量，这时候就很难判断是偏差还是方差了。

这时候需要设置一个新的集合，`trainning-dev set`让他有与训练集相同的分布，但不是拿来做训练的。

这样就可以判断出训练的能力，比如偏差还是方差就可以很容易判断出来了。

<!--惊人的想法！-->

human--【偏差】--训练误差--【方差】--`trainning-dev set`--【数据集问题】--dev set

### 数据不匹配问题

- 试着找到两者间的本质区别。
- 构造更相似的数据集，找到更多的相似数据。

比如人工构造数据。

但注意，不要使用同样的噪音。构造的过程中也需要符合随机法。

以及，人工合成的也只是所有数据中的一部分，甚至可能只是很小的以及子集。注意避免过拟合。

### 迁移学习

比如使用从分猫器中学到的部分知识，在分鸟器上做。

简单的做法就是，去掉最后一层或者几层，并随机重新赋值。然后再来做迭代。

<!--这个是基于一种可能性的认识，只有在最后一层才会有完整的判断？-->

这样的训练集被称为预初始化训练集，后面的迭代叫做微调。

<!--阿里等客户端上的深度学习，是不是大致就是这个技术啊？-->

