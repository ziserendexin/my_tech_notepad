# 概率论

对于机器学习使用概率的原因：

1. 虽然硬件错误不太容易发生，但的确有发生。
2. 机器学习必须处理不确定，同时也要处理随机性。

不确定来源于：

1. 被建模系统的内在随机
2. 不完全观测
3. 不完全建模

同时，就算是规则，也无法准确，完善地描述事实。比如：“鸟儿都会飞”，但要是细细研究下去，没办法划出一条明确的线。

<!--这玩意在哲学上叫做啥来着？-->

对于可以确定频率，或者说可以从频率推导出概率的，这种被称为**频率派概率（frequentist probability）**。

对于只能用**信任度(degree of belief)**表示的，设计到确定性水平的概率，被称为**贝叶斯概率(Bayesian probability)**。

概率可以被看做是用于处理不确定性的逻辑拓展：

逻辑提供一套形式化规则，可以在给定某些命题的真假后，判断另外一些命题的真假。

概率提供了一套形式化的规则，在给定一些命题的似然估计后，计算其他命题的似然估计。

## 离散

随机变量

概率分布

离散的随机变量的概率分布，使用**概率质量函数(PMF)**（也被称为概率分布函数），来进行描述，使用P来表示。每一个随便变量都有对应的PMF。这个需要注意。PS：P(X)与P(Y)就不是一个东西。

对于$P(X=x_1)$,表示随机变量在取$x_1$时的概率。通常需要先拟定一个随机变量$x$,然后说明他遵循概率分布：$x\sim P(X)$。如果有多个随机变量，那么被称为联合概率分布。

## 连续

就是被称为**概率密度函数(probability density function,PDF)**。

这个没有给出概率，只有落在面积为$\delta x$范围内的概率$p(x)\delta x​$。

## 条件概率

$$
P(Y=y|X=x)=\frac{P(Y=y,X=x)}{P(X=x)}
$$

> 不要把**条件概率**与计算“当采取某个动作后会发生什么”产生混淆。
>
> 比如，假定某个人会说德语，那么他是德国人的概率很高。
>
> 但如果是，随机选择一个人会说德语，他的国籍不会因此而改变。
>
> 计算一个行动的后果，被称为干预查询，这个属于因果模型的范畴，不讨论。

## 期望、方差、协方差

期望$E(X)$,方差$Var(X)$。

协方差给出了两个变量的**线性相关性**的强度.
$$
{\displaystyle \operatorname {cov} (X,Y)=\operatorname {E} ((X-\mu )(Y-\nu ))=\operatorname {E} (X\cdot Y)-\mu \nu .}
$$
还有对n个随机变量组成的协方差矩阵。

注意，协方差只是代表了线性相关性，与实际相关性，还相差很远。

<!--顺带一说，飞天面条神教就是疯狂黑那些滥用协方差的研究。-->

协方差为0，不代表独立性为0.

## 常用分布

### 伯努利分布

两点分布、0-1分布、二项分布。

### 多项分布(二项分布的拓展，k个状态)

### 高斯分布(正太分布)

若[随机变量](https://zh.wikipedia.org/wiki/%E9%9A%A8%E6%A9%9F%E8%AE%8A%E9%87%8F)${\displaystyle X}​$服从一个位置参数为${\displaystyle \mu }​$、尺度参数为${\displaystyle \sigma }​$的正态分布，记:
$$
X \sim N(\mu,\sigma^2)
$$
其概率密度函数为:
$$
f(x) = {1 \over \sigma\sqrt{2\pi} }\,e^{- {{(x-\mu )^2 \over 2\sigma^2}}}
$$
期望为${\displaystyle \mu }$，方差为${\displaystyle \sigma^2 }$。

其可以说是许多许多的二项分布的叠加态。

- 由**中心极限定理**可以得出，很多独立随机变量的和，近似服从正太分布。
- 具有相同方差的概率分布中，正太分布在实数上有最大的不确定性，可以认为其实对模型加入的先验知识最少的分布。

### 指数分布

$$
f(x;\lambda) = \left\{\begin{matrix}
\lambda e^{-\lambda x} &,\; x \ge 0, \\
0 &,\; x < 0.
\end{matrix}\right.
$$

其主要来源于**泊松过程**：

简单来说，就是对于二项分布在时间上的累计，近似于指数分布。

同时注意，泊松过程是**无记忆性**的。

与之相关的还有个**拉普拉斯分布**

### Dirac分布 狄拉克分布

一个迷一般的分布，所有质量都集中于一点，其他点都为0。

说着有带你夸张，但拉成均匀分布（经验分布），就正常了。

## 分布的混合

正太分布式概率密度的万能近似器，任何平衡的概率密度都可以用足够多的高斯混合来进行逼近。

<!--这话怎么这么耳熟啊，任意周期曲线用sin逼近。-->

## 连续变量的细节

连续型随机变量和概率密度函数的深入，需要考虑**测度论**进行扩展。

但会用到一些概念，比如 **零测度**、**几乎处处**。

<!--天国的几乎处处连续、几乎处处收敛、依测度收敛、连续、收敛。。-->

## 信息论

## 结构化概率模型

