对于有很多元素的线性回归的解法

### 符号表示

$n$：来表示有多少个特性

$x^{(i)}$：表示输入的第$i$个训练样本

$x_j^{(i)}$：表示输入的第$i$个训练样本的第$j$个值。

这里表示为$h_\theta(x)=\theta^T x$。

https://zhuanlan.zhihu.com/p/33899560

通过矩阵推导可知：

最优解$w=((X^TX)^{-1}X^Ty)$,这里$w$即是$\theta$。

但也因为这个cost function是二次的，所以也不需要担心局部最优，迭代法效果很好。

##### 关于迭代法的优化：

- **均值归一化**:

  将其都缩放到1.这样可以改变形状，加快速度。

  当然这里对前面求逆的地方也会不好用。

- **学习率**：

### 多项式拟合

考虑高次幂喽。

### 正规方程

直接求出解析解。$w=((X^TX)^{-1}X^Ty)$

## 测试：

第一题：真不懂了

最后一题:

